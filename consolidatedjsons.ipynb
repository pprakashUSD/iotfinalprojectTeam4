{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10fbdcc",
   "metadata": {},
   "source": [
    "## Final Project: Loading JSON data and consolidating into one CSV File\n",
    "#### Author Prakash Perimbeti\n",
    "#### Date: 02/16/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96e5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard imports\n",
    "import sys\n",
    "import os\n",
    "from os.path import exists\n",
    "import ecg_plot\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7017f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check converted consolidated csv file is available\n",
    "\n",
    "def getConsolidatedData(filename):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    file_exists = exists(filename)\n",
    "\n",
    "    if file_exists:\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        result = list(Path(\".\").rglob(\"*.[jJ][sS][oO][nN]\"))\n",
    "        print(len(result))\n",
    "        # Read json files from List\n",
    "        total = pd.concat(map(pd.read_json, result))\n",
    "        print(len(result), \"files:\", total.shape[0], total.shape[1])\n",
    "        total.head(5)\n",
    "        final = []\n",
    "        for i in range(len(result)):\n",
    "            tmp = pd.read_json(result[i])\n",
    "            axM = getMagnitudeList(tmp)\n",
    "            axV = getVelocityList(tmp)\n",
    "            timelist =  getTimeSeconds(tmp)\n",
    "            cont =  getContractility(tmp)\n",
    "            tmp['magnitude'] = axM\n",
    "            tmp['velocity'] = axV\n",
    "            tmp['timesecs'] = timelist\n",
    "            tmp['contractility'] = cont\n",
    "\n",
    "            final.append(tmp)\n",
    "        #print(\"Processed\",i, result[i], tmp.shape)\n",
    "        print(len(final))\n",
    "        df = pd.concat(final)\n",
    "        print(df.shape)\n",
    "        df.to_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f60c8",
   "metadata": {},
   "source": [
    "## Calculating Magnitude with accelorometer data\n",
    "- The acceleration signals were re-sampled to a standard sampling rate of 500 Hz.\n",
    "- The static gravity component of the acceleration signal was removed with a moving average filter (Tukey window of length 3 s with a cosine fraction of 0.5).\n",
    "- To further reduce the variability of the input data, we used the magnitude of the acceleration only (amagnitude=SQRT(ax ** 2 + ay ** 2 + az ** 2)).\n",
    "- Using the magnitude makes the approach insensitive to the orientation of the sensor axes, which is an advantage when attaching the sensor as it can be attached without concern for a specific orientation relative to the heart axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a516a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.integrate.cumtrapz(y, x=None, dx=1.0, axis=-1, initial=None)\n",
    "# average acc (xyg)\n",
    "def getMagnitudeList(df):\n",
    "    axeM = []\n",
    "    length = df.shape[0]\n",
    "    # Loop through the array to consider\n",
    "    # every window of size 3\n",
    "    i=0\n",
    "    #we used the magnitude of the acceleration only (amagnitude=âˆša2x+a2y+a2z).\n",
    "    while i < length:\n",
    "        x2 = df['acc_x'][i]**2\n",
    "        y2 = df['acc_y'][i]**2\n",
    "        z2 = df['acc_z'][i]**2\n",
    "        axeM.append(math.sqrt(x2+y2+z2))\n",
    "        i = i+1\n",
    "    #momentum\n",
    "    #df['momentum'] = axeM\n",
    "    return axeM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854357a",
   "metadata": {},
   "source": [
    "## Converting to velocity\n",
    "\n",
    "- The sensor in itself can't provide you the velocity.\n",
    "- The easiest way to get the velocity is to constantly monitor acceleration changes and calculate velocity instantaneaously.\n",
    "- The equation of motion (V = Vo + at)... The sensor will provide you value of acceleration at any given time.\n",
    "- Acceleration can vary quite significantly during a huge time intervals so keep the time intervals 't' small. Lets say t = 2ms (depends on you).\n",
    "- Calculate V after every 10ms intervale and this will give you current velocity at any given time.\n",
    "- But what about Vo? As you know it is refered to as initial velocity so in the beginning it will be 0. Immediately after first reading when you are about to take second reading the Vo will change to the previous V calculated and hence forth.\n",
    "- This means Vo at any given interval is actually the V calculated in the previous interval.\n",
    "- I tried this method in my project when using accelerometer. hope it helps you as well.\n",
    "- velocity = scipy.integrate.simps(acc, dx=dt) v = sqrt(Vx*Vx + Vy*Vy + Vz*Vz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164068c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVelocityList(df):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    vel = []\n",
    "    dt = 1/500\n",
    "    i=0\n",
    "    length = df.shape[0]\n",
    "    for i in range(length):\n",
    "        start = i\n",
    "        end = start + 2;\n",
    "        if(end > df.shape[0]):\n",
    "            #last value repeat the same as before for entire dataset\n",
    "            vel.append(math.sqrt(Vx*Vx + Vy*Vy + Vz*Vz))\n",
    "        else:\n",
    "            dtmp = df[start:end]\n",
    "            Vx = scipy.integrate.simps(dtmp['acc_x'], dx=dt)\n",
    "            Vy = scipy.integrate.simps(dtmp['acc_y'], dx=dt)\n",
    "            Vz = scipy.integrate.simps(dtmp['acc_z'], dx=dt)\n",
    "            vel.append(math.sqrt(Vx*Vx + Vy*Vy + Vz*Vz))\n",
    "        i = i+1\n",
    "    return vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e65122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeconds(df):\n",
    "    size = df.shape[0]\n",
    "    timelist = []\n",
    "    for i in range(size):\n",
    "        seconds, milliseconds = divmod((i+1)*2,1000) #500hz frequency\n",
    "        time = seconds + milliseconds/1000\n",
    "        timelist.append(time)\n",
    "    return timelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20baeed1",
   "metadata": {},
   "source": [
    "## Measure of Contractility\n",
    "- Contractility refers to the property of heart muscle that accounts for alterations in performance induced by biochemical and hormonal changes.\n",
    "- It has classically been regarded to be independent of preload and afterload. Contractility is generally used as a synonym for inotropy\n",
    "- Both terms refer to the level of activation of cross-bridge cycling during systole.\n",
    "- Contractility changes are assessed in the experimental laboratory by measuring myocardial function (extent or speed of shortening, maximum force generation) while preload and afterload are held constant.\n",
    "- In contrast to skeletal muscle, the strength of contraction of heart muscle can be increased readily by a variety of biochemical and hormonal stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "702aa740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContractility(df):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    contract = []\n",
    "    dt = 1/500\n",
    "    i=0\n",
    "    length = df.shape[0]\n",
    "    cont = 0.0\n",
    "    for i in range(length):\n",
    "        start = i\n",
    "        end = start + 2;\n",
    "        if(end > df.shape[0]):\n",
    "            #last value repeat the same as before for entire dataset\n",
    "            contract.append(cont)\n",
    "        else:\n",
    "            dtmp = df[start:end]\n",
    "            cont = scipy.integrate.simps(dtmp['lvp'], dx=dt)\n",
    "            contract.append(cont)\n",
    "        i = i+1\n",
    "    return contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301e1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Mac\n",
    "#%cd /Users/prakashperimbeti/desktop/AAI-USD/AAI-530/finalproject/epicardially-attached-cardiac-accelerometer-data-from-canines-and-porcines-1.0.0/accelerometer_data\n",
    "#In ubuntu server\n",
    "#%cd /home/bear/prakash/iot/finalproject/epicardially-attached-cardiac-accelerometer-data-from-canines-and-porcines-1.0.0/accelerometer_data\n",
    "#%ls\n",
    "\n",
    "# Running in ipynb uncomment one line after cd to root of data directories\n",
    "\n",
    "#############################\n",
    "# Execution of this takes aproximately 41 minutes even in fast server\n",
    "#############################\n",
    "#dfFinal = getConsolidatedData(\"./consolidated_ep_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bafe654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total arguments passed: 3\n",
      "\n",
      "Name of Python script: /home/bear/.local/lib/python3.10/site-packages/ipykernel_launcher.py\n",
      "\n",
      "Arguments passed: -f /home/bear/.local/share/jupyter/runtime/kernel-25626198-b0a1-46ae-8463-51f87778a01c.json \n",
      "\n",
      ":Arguments 3\n",
      "creating consolidated data file in the following directory: -f\n",
      "Directory exists: False\n",
      "Provided directory: -f  DOESN'T EXISTS!\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "#   Command line running\n",
    "#   MAIN PROGROM TO CONOLIDATE JSONs\n",
    "############################\n",
    "\n",
    "# total arguments\n",
    "n = len(sys.argv)\n",
    "print(\"Total arguments passed:\", n)\n",
    "\n",
    "# Arguments passed\n",
    "print(\"\\nName of Python script:\", sys.argv[0])\n",
    "\n",
    "print(\"\\nArguments passed:\", end = \" \")\n",
    "for i in range(1, n):\n",
    "    print(sys.argv[i], end = \" \")\n",
    "\n",
    "# Addition of numbers\n",
    "print(\"\\n\\n:Arguments\", n)\n",
    "if (n <= 1):\n",
    "        print(\"USAGE -> python3 consolidatedjsons.py <directory>\")\n",
    "        exit\n",
    "else:\n",
    "        print(\"creating consolidated data file in the following directory:\", sys.argv[1])\n",
    "        dir_exists = exists(sys.argv[1])\n",
    "        print(\"Directory exists:\", dir_exists)\n",
    "        if (dir_exists == True):\n",
    "                filename = sys.argv[1] + \"/consolidated_ep_data.csv\"\n",
    "                print(\"Consolidating all JSON Files\")\n",
    "                df = getConsolidatedData(filename)\n",
    "                print(\"Successfully consolidated data into one CSV\")\n",
    "                print(df.shape)\n",
    "                print(df.head(5))\n",
    "        else:\n",
    "                print(\"Provided directory:\", sys.argv[1],\" DOESN'T EXISTS!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b65815",
   "metadata": {},
   "source": [
    "## Running consolidatedjsons.py to create one CSV File\n",
    "- Go to command prompt and run python3 consolidatedjsons.py <path where root of accelerometer_data is located>\n",
    "- Example python3 consolidatedjsons.py $HOME/prakash/iot/finalproject/epicardially-attached-cardiac-accelerometer-data-from-canines-and-porcines-1.0.0/accelerometer_data\n",
    "- This creates one consolidated consolidated_ep_data.csv which is aproximately 700MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc3efa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
